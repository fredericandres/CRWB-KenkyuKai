{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning unsig the UEC FOOD-256 \n",
    "\n",
    "This notebook will be used to build a model to classifiy dishes with a pre-trained [ImageNet](http://www.image-net.org/) model from the MXNet [model zoo](http://data.mxnet.io/models/) and the  [UEC FOOD 256](http://foodcam.mobi/dataset256.zip) dataset. \n",
    "\n",
    "All of the network’s weights will be updated and also replaced in the last fully-connected layer with the new number of output classes by a smaller learning rate. For more in depth reading on fine-tuning with MXNet check this [tutorial](http://mxnet.io/how_to/finetune.html) and for more details on the how CNN's work check out [CS231n course](http://cs231n.github.io/convolutional-networks/#overview) and [MNIST example](https://github.com/dmlc/mxnet-notebooks/blob/master/python/tutorials/mnist.ipynb) with MXNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "# download function\n",
    "import os, urllib\n",
    "\n",
    "def download(url, location):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    document = os.path.join(location, filename)\n",
    "    if not os.path.exists(document):\n",
    "        urllib.urlretrieve(url, document)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.- Set the root path and the temp path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root = \"/media/\"\n",
    "temp = os.path.join(root, \"sf_Temp/UECFOOD-256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.- Set the dataset path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1.- Download the dataset [UEC FOOD 256](http://foodcam.mobi/dataset256.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download(\"http://foodcam.mobi/dataset256.zip\", temp)\n",
    "\n",
    "#dataset = os.path.join(root, \"sf_Datasets/UECFOOD-256.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2.- Extract the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import zipfile\n",
    "\n",
    "#archiver = zipfile.ZipFile(dataset, 'r')\n",
    "#archiver.extractall(temp)\n",
    "#archiver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = os.path.join(root, \"sf_Datasets/UECFOOD-256\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.- Create two folders: \"train\" and \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "train = os.path.join(temp, \"train\")\n",
    "\n",
    "if os.path.exists(train):\n",
    "    shutil.rmtree(train)\n",
    "    \n",
    "os.makedirs(train)\n",
    "    \n",
    "validation = os.path.join(temp, \"validation\")\n",
    "\n",
    "if os.path.exists(validation):\n",
    "    shutil.rmtree(validation)\n",
    "\n",
    "os.makedirs(validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1- Create additonal directories to get a directory structure as shown below:\n",
    "\n",
    "```\n",
    "    train/\n",
    "\n",
    "    ├── 0category\n",
    "    ├── ..category\n",
    "    └── icategory\n",
    "\n",
    "    validation/\n",
    "\n",
    "    ├── 0category\n",
    "    ├── ..category\n",
    "    └── icategory\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.- Move all data into train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2, imghdr\n",
    "import pandas as pd\n",
    "\n",
    "#metafile = \"category.txt\" \n",
    "\n",
    "#path = os.path.join(dataset, metafile)\n",
    "#if os.path.isfile(path):\n",
    "    #shutil.copy2(path, os.path.join(train, metafile))\n",
    "\n",
    "metafile = \"bb_info.txt\"  \n",
    "\n",
    "for category, categories, files in os.walk(dataset):\n",
    "    path = os.path.join(category, metafile)\n",
    "    df = None\n",
    "    if os.path.isfile(path):\n",
    "        df = pd.read_csv(os.path.join(category, metafile), delim_whitespace = True, index_col = 0)\n",
    "        #shutil.copy2(path, os.path.join(category, metafile))\n",
    "    for document in files:\n",
    "        path = os.path.join(category, document)\n",
    "        if imghdr.what(path) is not None:\n",
    "            image = cv2.imread(os.path.join(category, document))\n",
    "            name = os.path.splitext(document)[0]\n",
    "            boxes = df.loc[[int(name)]]\n",
    "            for i, (index, box) in enumerate(boxes.iterrows()): \n",
    "                x1 = box.loc[\"x1\"]\n",
    "                x2 = box.loc[\"x2\"]\n",
    "                y1 = box.loc[\"y1\"]\n",
    "                y2 = box.loc[\"y2\"]\n",
    "                cropped = image[y1:y2, x1:x2];\n",
    "                cv2.imwrite(os.path.join(train, os.path.basename(category), str(i) + document), cropped)\n",
    "        #else:\n",
    "            #shutil.copy2(path, os.path.join(train, os.path.basename(category)))\n",
    "    for directory in categories:\n",
    "        path = os.path.join(train, directory)\n",
    "        if os.path.exists(path):\n",
    "            shutil.rmtree(path)\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.- Move a percentage of the data in to the validation directory to create the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# 20%\n",
    "percentage = 20.0\n",
    "      \n",
    "for category, categories, files in os.walk(train):\n",
    "    size = int(len(files) / percentage)\n",
    "    for name in random.sample(files, size):\n",
    "        if imghdr.what(os.path.join(train, category, name)) is not None:\n",
    "            shutil.move(os.path.join(category, name), os.path.join(validation, os.path.basename(category)))\n",
    "    for name in categories:\n",
    "        directory = os.path.join(validation, name)\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.- Create a list for training and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "    \n",
    "im2rec = os.path.join(os.path.dirname(mx.__file__), \"tools/im2rec.py\")\n",
    "\n",
    "import subprocess\n",
    "\n",
    "trainning_list = os.path.join(train, \"train\")\n",
    "\n",
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(train):\n",
    "        subprocess.call([\"python\", im2rec, \"--list\", \"True\", \"--recursive\",\"True\", trainning_list, train])\n",
    "\n",
    "validation_list = os.path.join(validation, \"validation\")        \n",
    "        \n",
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(validation):\n",
    "        subprocess.call([\"python\", im2rec, \"--list\",\"True\", \"--recursive\", \"True\", validation_list, validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.- Convert the images in to MXNet RecordIO format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(train):\n",
    "        subprocess.call([\"python\", im2rec, \"--resize\", \"224\", \"--quality\",\"90\", \"--num-thread\", \"16\", trainning_list, train])\n",
    "\n",
    "if os.path.isfile(im2rec):\n",
    "    if os.path.exists(validation):\n",
    "        subprocess.call([\"python\", im2rec, \"--resize\", \"224\", \"--quality\", \"90\", \"--num-thread\", \"16\", validation_list, validation])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data_train.rec and data_validation.rec files should be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/sf_Temp/train/train.idx\n",
      "/media/sf_Temp/train/train.lst\n",
      "/media/sf_Temp/train/train.rec\n",
      "/media/sf_Temp/validation/validation.idx\n",
      "/media/sf_Temp/validation/validation.lst\n",
      "/media/sf_Temp/validation/validation.rec\n"
     ]
    }
   ],
   "source": [
    "for directory, directories, files in os.walk(train):\n",
    "    for document in files:\n",
    "        path = os.path.join(directory, document)\n",
    "        if imghdr.what(path) is None:\n",
    "            print path\n",
    "            \n",
    "for directory, directories, files in os.walk(validation):\n",
    "    for document in files:\n",
    "        path = os.path.join(directory, document)\n",
    "        if imghdr.what(path) is None:\n",
    "            print path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE\n",
    "\n",
    "The function below returns the data iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Iterators for cats vs dogs dataset\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    trainning_iterator = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = os.path.join(train, \"train.rec\"), \n",
    "        data_name           = \"data\",\n",
    "        label_name          = \"softmax_label\",\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    validation_iterator = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = os.path.join(validation, \"validation.rec\"),\n",
    "        data_name           = \"data\",\n",
    "        label_name          = \"softmax_label\",\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (trainning_iterator, validation_iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dowload pre-trained model from the model zoo (ResidualNet152)\n",
    "\n",
    "Download a pre-trained 152-layer ResNet model and load into memory.\n",
    "\n",
    "    Note: If load_checkpoint reports error the downloaded files need to be removed before to try get the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download function\n",
    "def get_model(prefix, epoch, location):\n",
    "    download(prefix + \"-symbol.json\", location)\n",
    "    download(prefix + \"-%04d.params\" % (epoch,), location)\n",
    "\n",
    "get_model(\"http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152\", 0, temp)\n",
    "\n",
    "symbol, arg_params, aux_params = mx.model.load_checkpoint(os.path.join(temp, \"resnet-152\"), 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the model\n",
    "\n",
    "\n",
    "To fine-tune a network, the last fully-connected layer with must be replace by a new one that outputs the desired number of classes. The weights are initialize randomly. Then training will continue normaly. Sometimes it’s common use a smaller learning rate based on the intuition that good result may already be reached.\n",
    "\n",
    "First of all, a function which replaces the the last fully-connected layer for a given network needs to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(sym, arg_params, num_classes, layer_name = \"flatten0\"):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers[layer_name + \"_output\"]\n",
    "    net = mx.symbol.FullyConnected(data = net, num_hidden = num_classes, name = \"fc1\")\n",
    "    net = mx.symbol.SoftmaxOutput(data = net, name = \"softmax\")\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if \"fc1\" not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "A fit function that creates an MXNet module instance needs to be defined to bind the data and symbols. \n",
    "\n",
    "init_params is called to randomly initialize parameters\n",
    "\n",
    "set_params is called to replace all parameters except for the last fully-connected layer with pre-trained model.\n",
    "\n",
    "#### Note: change mx.cpu to mx.gpu to run training on GPU (much faster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level = logging.DEBUG, format = \"%(asctime)-15s %(message)s\")\n",
    "\n",
    "def fit(sym, arg_params, aux_params, train_iter, val_iter, batch_size, num_pus = 1, num_epoch = 1):\n",
    "    devs = [mx.cpu(i) for i in range(num_pus)] # replace mx.cpu by mx.gpu for GPU training\n",
    "    mod = mx.mod.Module(symbol = new_sym, context = devs)\n",
    "    mod.bind(data_shapes = train_iter.provide_data, label_shapes = train_iter.provide_label)\n",
    "    mod.init_params(initializer = mx.init.Xavier(rnd_type = \"gaussian\", factor_type = \"in\", magnitude = 2))\n",
    "    mod.set_params(new_args, aux_params, allow_missing = True)\n",
    "    mod.fit(\n",
    "        train_iter, \n",
    "        val_iter, \n",
    "        num_epoch = num_epoch,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 10),        \n",
    "        kvstore = \"device\",\n",
    "        optimizer = \"sgd\",\n",
    "        optimizer_params = {\"learning_rate\":0.009},\n",
    "        eval_metric ='acc'\n",
    "    )\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the helper functions are setup and training can to start.\n",
    "Its recommended that to train on a GPU instance, preferably p2.* family. For this notebook an AWS EC2 p2.xlarge, which has one NVIDIA K80 GPU, was considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MXNetError",
     "evalue": "[11:07:54] src/io/input_split_base.cc:163: Check failed: files_.size() != 0U (0 vs. 0) Cannot find any files that matches the URI patternz /media/sf_Temp/UECFOOD-256/train/train.rec\n\nStack trace returned 10 entries:\n[bt] (0) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xc72fc) [0x7f09463bd2fc]\n[bt] (1) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xf96de3) [0x7f094728cde3]\n[bt] (2) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xf97d0e) [0x7f094728dd0e]\n[bt] (3) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xf67e6e) [0x7f094725de6e]\n[bt] (4) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xbceea4) [0x7f0946ec4ea4]\n[bt] (5) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xbcf6cd) [0x7f0946ec56cd]\n[bt] (6) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(MXDataIterCreateIter+0x1c0) [0x7f0946de4a10]\n[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f098697ae18]\n[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x32a) [0x7f098697a87a]\n[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x2d4) [0x7f0986b8e214]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMXNetError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7942930ab609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_per_pu\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_pus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_iterators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_sym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-e5dc28cd4f11>\u001b[0m in \u001b[0;36mget_iterators\u001b[0;34m(batch_size, data_shape)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mshuffle\u001b[0m             \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mrand_crop\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         rand_mirror         = True)\n\u001b[0m\u001b[1;32m     13\u001b[0m     validation_iterator = mx.io.ImageRecordIter(\n\u001b[1;32m     14\u001b[0m         \u001b[0mpath_imgrec\u001b[0m         \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"validation.rec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/mxnet/io.pyc\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m             \u001b[0mmx_uint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0mparam_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             ctypes.byref(iter_handle)))\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.local/lib/python2.7/site-packages/mxnet/base.pyc\u001b[0m in \u001b[0;36mcheck_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMXNetError\u001b[0m: [11:07:54] src/io/input_split_base.cc:163: Check failed: files_.size() != 0U (0 vs. 0) Cannot find any files that matches the URI patternz /media/sf_Temp/UECFOOD-256/train/train.rec\n\nStack trace returned 10 entries:\n[bt] (0) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xc72fc) [0x7f09463bd2fc]\n[bt] (1) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xf96de3) [0x7f094728cde3]\n[bt] (2) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xf97d0e) [0x7f094728dd0e]\n[bt] (3) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xf67e6e) [0x7f094725de6e]\n[bt] (4) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xbceea4) [0x7f0946ec4ea4]\n[bt] (5) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(+0xbcf6cd) [0x7f0946ec56cd]\n[bt] (6) /home/ubuntu/.local/lib/python2.7/site-packages/mxnet/libmxnet.so(MXDataIterCreateIter+0x1c0) [0x7f0946de4a10]\n[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f098697ae18]\n[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x32a) [0x7f098697a87a]\n[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x2d4) [0x7f0986b8e214]\n"
     ]
    }
   ],
   "source": [
    "num_classes = 256 # Number of categories\n",
    "batch_per_pu = 4\n",
    "num_pus = 1\n",
    "(new_sym, new_args) = get_fine_tune_model(symbol, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_pu * num_pus\n",
    "(train_iter, val_iter) = get_iterators(batch_size)\n",
    "mod = fit(new_sym, new_args, aux_params, train_iter, val_iter, batch_size, num_pus)\n",
    "metric = mx.metric.Accuracy()\n",
    "mod_score = mod.score(val_iter, metric)\n",
    "print mod_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the newly trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefix = \"resnet-mxnet-dishes\"\n",
    "epoch = 1\n",
    "\n",
    "mc = mod.save_chekpoint(prefix, epoch)\n",
    "\n",
    "for document in os.listdir(\"./\"):\n",
    "    if (document.startswith(prefix)):\n",
    "        shutil.move(document, temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "\n",
    "dshape = [('data', (1,3,224,224))]\n",
    "\n",
    "def load_model(s_fname, p_fname):\n",
    "    \"\"\"\n",
    "    load model checkpoint from file.\n",
    "    :return: (arg_params, aux_params)\n",
    "    arg_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's weights.\n",
    "    aux_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's auxiliary states.\n",
    "    \"\"\"\n",
    "    symbol = mx.symbol.load(s_fname)\n",
    "    save_dict = mx.nd.load(p_fname)\n",
    "    arg_params = {}\n",
    "    aux_params = {}\n",
    "    for k, v in save_dict.items():\n",
    "        tp, name = k.split(':', 1)\n",
    "        if tp == 'arg':\n",
    "            arg_params[name] = v\n",
    "        if tp == 'aux':\n",
    "            aux_params[name] = v\n",
    "    return symbol, arg_params, aux_params\n",
    "       \n",
    "model_symbol = None\n",
    "model_params = None\n",
    "\n",
    "for document in os.listdir(temp):\n",
    "    filename, extension = os.path.splitext(document)\n",
    "    if (filename.startswith(prefix)):\n",
    "        if(extension == \"json\"):\n",
    "            model_symbol = document\n",
    "        if(extension == \"params\"):\n",
    "            model_params = document\n",
    "\n",
    "symbol, arg_params, aux_params = load_model(model_symbol, model_params)\n",
    "mod = mx.mod.Module(symbol = symbol)\n",
    "\n",
    "# bind the model, set training to False and define the data shape\n",
    "mod.bind(for_training = False, data_shapes = dshape)\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions for an arbitrary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def preprocess_image(img, show = False):\n",
    "    '''\n",
    "    convert the image to a numpy array\n",
    "    '''\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2) \n",
    "    img = img[np.newaxis, :] \n",
    "    return img\n",
    "\n",
    "url = 'https://cdn.pixabay.com/photo/2016/03/05/19/02/abstract-1238248_640.jpg'\n",
    "request = urllib2.urlopen(url)\n",
    "\n",
    "image = np.asarray(bytearray(req.read()), dtype = \"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "image = preprocess_image(image)\n",
    "\n",
    "mod.forward(Batch([mx.nd.array(image)]))\n",
    "\n",
    "# predict\n",
    "prob = mod.get_outputs()[0].asnumpy()\n",
    "print prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inspecting incorrect labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
