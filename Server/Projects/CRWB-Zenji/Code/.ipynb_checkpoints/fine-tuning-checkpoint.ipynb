{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning \n",
    "\n",
    "This notebook will be used to build a model to classifiy dishes with a pre-trained [ImageNet](http://www.image-net.org/) model from the MXNet [model zoo](http://data.mxnet.io/models/). \n",
    "\n",
    "All of the network’s weights will be updated and also replaced in the last fully-connected layer with the new number of output classes by a smaller learning rate. For more in depth reading on fine-tuning with MXNet check this [tutorial](http://mxnet.io/how_to/finetune.html) and for more details on the how CNN's work check out [CS231n course](http://cs231n.github.io/convolutional-networks/#overview) and [MNIST example](https://github.com/dmlc/mxnet-notebooks/blob/master/python/tutorials/mnist.ipynb) with MXNet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Pre-processing the dataset\n",
    "\n",
    "1. Download the data.\n",
    "\n",
    "2. Create two folders \"train\" and \"valid\".\n",
    "\n",
    "3. Create additonal directories to get a directory structure as shown below:\n",
    "\n",
    "```\n",
    "    train/\n",
    "\n",
    "    ├── 0category\n",
    "    ├── ..category\n",
    "    └── icategory\n",
    "\n",
    "    validation/\n",
    "\n",
    "    ├── 0category\n",
    "    ├── ..category\n",
    "    └── icategory\n",
    "```\n",
    "\n",
    "4. Move all data into train. \n",
    "\n",
    "5. Move a percentage of the data in to the validation directory to create the validation set. \n",
    "\n",
    "```\n",
    "    import os\n",
    "    import random\n",
    "    import shutil\n",
    "    \n",
    "    # helper functions\n",
    "\n",
    "    # download function\n",
    "    import os, urllib\n",
    "    def download(url):\n",
    "        filename = url.split(\"/\")[-1]\n",
    "        if not os.path.exists(filename):\n",
    "            urllib.urlretrieve(url, filename)\n",
    "\n",
    "    category_directory = 'train/category'\n",
    "\n",
    "    all_objects = os.listdir(category_directory)\n",
    "   \n",
    "    # 20%\n",
    "    p = 20.0\n",
    "    \n",
    "    N = int(len(all_objects)/p)\n",
    "\n",
    "    for f in random.sample(all_objects, N):\n",
    "       shutil.move(category_directory + \"/\" + f, \"validation/category/\" + f)\n",
    "\n",
    "```\n",
    "\n",
    "6. Create a list for training and validation set\n",
    "```\n",
    " python ~/mxnet/tools/im2rec.py --list True --recursive True data_train.lst data/train\n",
    "\n",
    " python ~/mxnet/tools/im2rec.py --list True --recursive True data_validation.lst data/validation\n",
    "```\n",
    "\n",
    "7. Convert the images in to MXNet RecordIO format\n",
    "```\n",
    " python ~/mxnet/tools/im2rec.py --resize 224 --quality 90 --num-thread 16 data_train.lst data/train\n",
    "\n",
    " python ~/mxnet/tools/im2rec.py --resize 224 --quality 90 --num-thread 16 data_validation.lst data/validation\n",
    "```  \n",
    "\n",
    "The data_train.rec and data_validation.rec files should be created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE\n",
    "\n",
    "The function below returns the data iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data Iterators for cats vs dogs dataset\n",
    "\n",
    "import mxnet as mx\n",
    "\n",
    "def get_iterators(batch_size, data_shape=(3, 224, 224)):\n",
    "    train = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './data_train.rec', \n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        shuffle             = True,\n",
    "        rand_crop           = True,\n",
    "        rand_mirror         = True)\n",
    "    val = mx.io.ImageRecordIter(\n",
    "        path_imgrec         = './data_validation.rec',\n",
    "        data_name           = 'data',\n",
    "        label_name          = 'softmax_label',\n",
    "        batch_size          = batch_size,\n",
    "        data_shape          = data_shape,\n",
    "        rand_crop           = False,\n",
    "        rand_mirror         = False)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dowload pre-trained model from the model zoo (ResidualNet152)\n",
    "\n",
    "Download a pre-trained 152-layer ResNet model and load into memory.\n",
    "\n",
    "    Note: If load_checkpoint reports error the downloaded files need to be removed before to try get the model again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "import os, urllib\n",
    "def download(url):\n",
    "    filename = url.split(\"/\")[-1]\n",
    "    if not os.path.exists(filename):\n",
    "        urllib.urlretrieve(url, filename)\n",
    "        \n",
    "def get_model(prefix, epoch):\n",
    "    download(prefix+'-symbol.json')\n",
    "    download(prefix+'-%04d.params' % (epoch,))\n",
    "\n",
    "get_model('http://data.mxnet.io/models/imagenet/resnet/152-layers/resnet-152', 0)\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-152', 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning the model\n",
    "\n",
    "\n",
    "To fine-tune a network, the last fully-connected layer with must be replace by a new one that outputs the desired number of classes. The weights are initialize randomly. Then training will continue normaly. Sometimes it’s common use a smaller learning rate based on the intuition that good result may already be reached.\n",
    "\n",
    "First of all, a function which replaces the the last fully-connected layer for a given network needs to be defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_fine_tune_model(symbol, arg_params, num_classes, layer_name='flatten0'):\n",
    "    \"\"\"\n",
    "    symbol: the pre-trained network symbol\n",
    "    arg_params: the argument parameters of the pre-trained model\n",
    "    num_classes: the number of classes for the fine-tune datasets\n",
    "    layer_name: the layer name before the last fully-connected layer\n",
    "    \"\"\"\n",
    "    all_layers = sym.get_internals()\n",
    "    net = all_layers[layer_name+'_output']\n",
    "    net = mx.symbol.FullyConnected(data=net, num_hidden=num_classes, name='fc1')\n",
    "    net = mx.symbol.SoftmaxOutput(data=net, name='softmax')\n",
    "    new_args = dict({k:arg_params[k] for k in arg_params if 'fc1' not in k})\n",
    "    return (net, new_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "A fit function that creates an MXNet module instance needs to be defined to bind the data and symbols. \n",
    "\n",
    "init_params is called to randomly initialize parameters\n",
    "\n",
    "set_params is called to replace all parameters except for the last fully-connected layer with pre-trained model.\n",
    "\n",
    "#### Note: change mx.gpu to mx.cpu to run training on CPU (much slower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "head = '%(asctime)-15s %(message)s'\n",
    "logging.basicConfig(level=logging.DEBUG, format=head)\n",
    "\n",
    "def fit(symbol, arg_params, aux_params, train, val, batch_size, num_gpus=1, num_epoch=1):\n",
    "    devs = [mx.gpu(i) for i in range(num_gpus)] # replace mx.gpu by mx.cpu for CPU training\n",
    "    mod = mx.mod.Module(symbol=new_sym, context=devs)\n",
    "    mod.bind(data_shapes=train.provide_data, label_shapes=train.provide_label)\n",
    "    mod.init_params(initializer=mx.init.Xavier(rnd_type='gaussian', factor_type=\"in\", magnitude=2))\n",
    "    mod.set_params(new_args, aux_params, allow_missing=True)\n",
    "    mod.fit(train, val, \n",
    "        num_epoch=num_epoch,\n",
    "        batch_end_callback = mx.callback.Speedometer(batch_size, 10),        \n",
    "        kvstore='device',\n",
    "        optimizer='sgd',\n",
    "        optimizer_params={'learning_rate':0.009},\n",
    "        eval_metric='acc')\n",
    "    \n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the helper functions are setup and training can to start.\n",
    "Its recommended that to train on a GPU instance, preferably p2.* family. For this notebook an AWS EC2 p2.xlarge, which has one NVIDIA K80 GPU, was considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = i # Number of categories\n",
    "batch_per_gpu = 4\n",
    "num_gpus = 1\n",
    "(new_sym, new_args) = get_fine_tune_model(sym, arg_params, num_classes)\n",
    "\n",
    "batch_size = batch_per_gpu * num_gpus\n",
    "(train, val) = get_iterators(batch_size)\n",
    "mod = fit(new_sym, new_args, aux_params, train, val, batch_size, num_gpus)\n",
    "metric = mx.metric.Accuracy()\n",
    "mod_score = mod.score(val, metric)\n",
    "print mod_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, save the newly trained model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-01 01:33:56,263 Saved checkpoint to \"resnet-mxnet-catsvsdogs-0001.params\"\n"
     ]
    }
   ],
   "source": [
    "prefix = 'resnet-mxnet-name'\n",
    "epoch = 1\n",
    "mc = mod.save_checkpoint(prefix, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "import cv2\n",
    "dshape = [('data', (1,3,224,224))]\n",
    "\n",
    "def load_model(s_fname, p_fname):\n",
    "    \"\"\"\n",
    "    load model checkpoint from file.\n",
    "    :return: (arg_params, aux_params)\n",
    "    arg_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's weights.\n",
    "    aux_params : dict of str to NDArray\n",
    "        Model parameter, dict of name to NDArray of net's auxiliary states.\n",
    "    \"\"\"\n",
    "    symbol = mx.symbol.load(s_fname)\n",
    "    save_dict = mx.nd.load(p_fname)\n",
    "    arg_params = {}\n",
    "    aux_params = {}\n",
    "    for k, v in save_dict.items():\n",
    "        tp, name = k.split(':', 1)\n",
    "        if tp == 'arg':\n",
    "            arg_params[name] = v\n",
    "        if tp == 'aux':\n",
    "            aux_params[name] = v\n",
    "    return symbol, arg_params, aux_params\n",
    "\n",
    "model_symbol = \"resnet-mxnet-name-symbol.json\"\n",
    "model_params = \"resnet-mxnet-param-000i.params\"\n",
    "sym, arg_params, aux_params = load_model(model_symbol, model_params)\n",
    "mod = mx.mod.Module(symbol=sym)\n",
    "\n",
    "# bind the model, set training to False and define the data shape\n",
    "mod.bind(for_training=False, data_shapes=dshape)\n",
    "mod.set_params(arg_params, aux_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions for an arbitrary image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.99993086e-01   6.96629468e-06]]\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "from collections import namedtuple\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "\n",
    "def preprocess_image(img, show_img=False):\n",
    "    '''\n",
    "    convert the image to a numpy array\n",
    "    '''\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.swapaxes(img, 0, 2)\n",
    "    img = np.swapaxes(img, 1, 2) \n",
    "    img = img[np.newaxis, :] \n",
    "    return img\n",
    "\n",
    "url = ''\n",
    "req = urllib2.urlopen(url)\n",
    "\n",
    "image = np.asarray(bytearray(req.read()), dtype=\"uint8\")\n",
    "image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "img = preprocess_image(image)\n",
    "\n",
    "mod.forward(Batch([mx.nd.array(img)]))\n",
    "\n",
    "# predict\n",
    "prob = mod.get_outputs()[0].asnumpy()\n",
    "print prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Inspecting incorrect labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate predictions for entire validation dataset\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "path = 'data/valid/category/' # change as needed\n",
    "files = [path + f for f in os.listdir(path)]\n",
    "incorrect_labels = []\n",
    "\n",
    "# incorrect category labels\n",
    "for f in files:\n",
    "    img = cv2.imread(f)\n",
    "    img = preprocess_image(img)\n",
    "    mod.forward(Batch([mx.nd.array(img)]))\n",
    "    prob = mod.get_outputs()[0].asnumpy()\n",
    "    if prob.argmax() != 1: # not a cat\n",
    "        print f\n",
    "        incorrect_labels.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "# plot helper\n",
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, len(ims)//rows, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
    "\n",
    "# individual plot of incorrect label\n",
    "img_path = incorrect_labels[0]\n",
    "plots([cv2.imread(img_path)])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
